<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.340">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Chirag Sharma">
<meta name="dcterms.date" content="2023-01-09">
<meta name="description" content="In this post, we’ll demonstrate how to scape data from flipkart using BeautifulSoup &amp; Selenium using Python.">

<title>Chirag Sharma - Multilingual Toxic Comment Classification using Tensorflow and TPUs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Chirag Sharma</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../resume/Chirag_Sharma_Resume.pdf" rel="" target="">
 <span class="menu-text">Resume</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Multilingual Toxic Comment Classification using Tensorflow and TPUs</h1>
                  <div>
        <div class="description">
          In this post, we’ll demonstrate how to scape data from flipkart using BeautifulSoup &amp; Selenium using Python.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Web Scrapping</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Chirag Sharma </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 9, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#problem-statement" id="toc-problem-statement" class="nav-link active" data-scroll-target="#problem-statement">Problem Statement</a></li>
  <li><a href="#dataset-description" id="toc-dataset-description" class="nav-link" data-scroll-target="#dataset-description">Dataset Description</a></li>
  <li><a href="#evaluation-metric" id="toc-evaluation-metric" class="nav-link" data-scroll-target="#evaluation-metric">Evaluation Metric</a></li>
  <li><a href="#strategies-to-tackle" id="toc-strategies-to-tackle" class="nav-link" data-scroll-target="#strategies-to-tackle">Strategies to Tackle</a>
  <ul class="collapse">
  <li><a href="#monolingual-approach" id="toc-monolingual-approach" class="nav-link" data-scroll-target="#monolingual-approach"><code>Monolingual Approach</code></a></li>
  <li><a href="#multilingual-approach" id="toc-multilingual-approach" class="nav-link" data-scroll-target="#multilingual-approach"><code>Multilingual Approach</code></a></li>
  <li><a href="#which-models-to-use-for-our-problem" id="toc-which-models-to-use-for-our-problem" class="nav-link" data-scroll-target="#which-models-to-use-for-our-problem"><code>Which models to use for our problem?</code></a></li>
  <li><a href="#cross-lingual-transfer" id="toc-cross-lingual-transfer" class="nav-link" data-scroll-target="#cross-lingual-transfer"><code>Cross Lingual Transfer</code></a></li>
  <li><a href="#what-experiments-did-i-perform" id="toc-what-experiments-did-i-perform" class="nav-link" data-scroll-target="#what-experiments-did-i-perform"><code>What experiments did I perform ?</code></a></li>
  </ul></li>
  <li><a href="#installing-libraries" id="toc-installing-libraries" class="nav-link" data-scroll-target="#installing-libraries">Installing Libraries</a></li>
  <li><a href="#setting-data-paths" id="toc-setting-data-paths" class="nav-link" data-scroll-target="#setting-data-paths">Setting data paths</a></li>
  <li><a href="#tpu-configurations" id="toc-tpu-configurations" class="nav-link" data-scroll-target="#tpu-configurations">TPU Configurations</a></li>
  <li><a href="#reading-balancing-the-data-by-target-column" id="toc-reading-balancing-the-data-by-target-column" class="nav-link" data-scroll-target="#reading-balancing-the-data-by-target-column">Reading &amp; Balancing the data by Target column</a></li>
  <li><a href="#encoding-comment_text" id="toc-encoding-comment_text" class="nav-link" data-scroll-target="#encoding-comment_text">Encoding comment_text</a></li>
  <li><a href="#preparing-data-using-tf.data.data-api" id="toc-preparing-data-using-tf.data.data-api" class="nav-link" data-scroll-target="#preparing-data-using-tf.data.data-api">Preparing data using tf.data.Data API</a></li>
  <li><a href="#building-the-model" id="toc-building-the-model" class="nav-link" data-scroll-target="#building-the-model">Building the model</a></li>
  <li><a href="#loading-model-on-tpus" id="toc-loading-model-on-tpus" class="nav-link" data-scroll-target="#loading-model-on-tpus">Loading model on TPUs</a></li>
  <li><a href="#training-the-model-on-only-english-data-for-2-epochs" id="toc-training-the-model-on-only-english-data-for-2-epochs" class="nav-link" data-scroll-target="#training-the-model-on-only-english-data-for-2-epochs">Training the model on Only English data for 2 epochs</a></li>
  <li><a href="#training-the-model-on-validation-data-for-2-epochs-further-to-fine-tune-on-it" id="toc-training-the-model-on-validation-data-for-2-epochs-further-to-fine-tune-on-it" class="nav-link" data-scroll-target="#training-the-model-on-validation-data-for-2-epochs-further-to-fine-tune-on-it">Training the model on Validation data for 2 epochs further to fine-tune on it</a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a></li>
  <li><a href="#predicting-on-test-dataset" id="toc-predicting-on-test-dataset" class="nav-link" data-scroll-target="#predicting-on-test-dataset">Predicting on Test dataset</a></li>
  <li><a href="#saving-the-model" id="toc-saving-the-model" class="nav-link" data-scroll-target="#saving-the-model">Saving the model</a></li>
  <li><a href="#loading-the-model" id="toc-loading-the-model" class="nav-link" data-scroll-target="#loading-the-model">Loading the model</a>
  <ul class="collapse">
  <li><a href="#testing-the-model-with-the-gradio-app-before-final-pushing-the-model-to-huggingface-spaces" id="toc-testing-the-model-with-the-gradio-app-before-final-pushing-the-model-to-huggingface-spaces" class="nav-link" data-scroll-target="#testing-the-model-with-the-gradio-app-before-final-pushing-the-model-to-huggingface-spaces">Testing the model with the Gradio App before final pushing the model to HuggingFace Spaces</a></li>
  </ul></li>
  <li><a href="#turning-our-multi-lingual-toxic-comment-classification-gradio-demo-into-a-deployable-app" id="toc-turning-our-multi-lingual-toxic-comment-classification-gradio-demo-into-a-deployable-app" class="nav-link" data-scroll-target="#turning-our-multi-lingual-toxic-comment-classification-gradio-demo-into-a-deployable-app">Turning our Multi-Lingual Toxic Comment Classification Gradio Demo into a deployable app</a>
  <ul class="collapse">
  <li><a href="#deployed-gradio-app-structure" id="toc-deployed-gradio-app-structure" class="nav-link" data-scroll-target="#deployed-gradio-app-structure">Deployed Gradio App Structure</a></li>
  <li><a href="#creating-a-demo-folder-to-store-our-multilingual-toxic-comment-classifier-app-files" id="toc-creating-a-demo-folder-to-store-our-multilingual-toxic-comment-classifier-app-files" class="nav-link" data-scroll-target="#creating-a-demo-folder-to-store-our-multilingual-toxic-comment-classifier-app-files">Creating a demo folder to store our Multilingual Toxic Comment Classifier App files</a></li>
  <li><a href="#creating-a-folder-of-example-images-to-use-with-our-melanoma-skin-cancer-demo" id="toc-creating-a-folder-of-example-images-to-use-with-our-melanoma-skin-cancer-demo" class="nav-link" data-scroll-target="#creating-a-folder-of-example-images-to-use-with-our-melanoma-skin-cancer-demo">Creating a folder of example images to use with our Melanoma skin cancer demo</a></li>
  <li><a href="#moving-our-trained-xlm-roberta-model-binary-files-into-our-multilingual_toxic_comment_files-demo-directory." id="toc-moving-our-trained-xlm-roberta-model-binary-files-into-our-multilingual_toxic_comment_files-demo-directory." class="nav-link" data-scroll-target="#moving-our-trained-xlm-roberta-model-binary-files-into-our-multilingual_toxic_comment_files-demo-directory.">Moving our trained XLM-Roberta model binary files into our multilingual_toxic_comment_files demo directory.</a></li>
  </ul></li>
  <li><a href="#turning-our-gradio-app-into-a-python-script-app.py" id="toc-turning-our-gradio-app-into-a-python-script-app.py" class="nav-link" data-scroll-target="#turning-our-gradio-app-into-a-python-script-app.py">Turning our Gradio App into a Python Script (<code>app.py</code>)</a>
  <ul class="collapse">
  <li><a href="#creating-a-requirements.txt-file-for-our-gradio-apprequirements.txt" id="toc-creating-a-requirements.txt-file-for-our-gradio-apprequirements.txt" class="nav-link" data-scroll-target="#creating-a-requirements.txt-file-for-our-gradio-apprequirements.txt">Creating a requirements.txt file for our Gradio App(<code>requirements.txt</code>)</a></li>
  </ul></li>
  <li><a href="#deploying-our-application-to-huggingface-spaces" id="toc-deploying-our-application-to-huggingface-spaces" class="nav-link" data-scroll-target="#deploying-our-application-to-huggingface-spaces">Deploying our Application to HuggingFace Spaces</a>
  <ul class="collapse">
  <li><a href="#running-our-application-locally" id="toc-running-our-application-locally" class="nav-link" data-scroll-target="#running-our-application-locally">Running our Application locally</a></li>
  <li><a href="#uploading-to-hugging-face" id="toc-uploading-to-hugging-face" class="nav-link" data-scroll-target="#uploading-to-hugging-face">Uploading to Hugging Face</a></li>
  </ul></li>
  <li><a href="#our-final-application-deployed-on-huggingface-spaces" id="toc-our-final-application-deployed-on-huggingface-spaces" class="nav-link" data-scroll-target="#our-final-application-deployed-on-huggingface-spaces">Our Final Application deployed on HuggingFace Spaces</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="problem-statement">Problem Statement</h2>
<p>The Conversation AI team, a research initiative founded by Jigsaw and Google builds a technology to prevent voices in Conversation. In 2020, Jigsaw organized a competition on Kaggle where the competitors has to build machine learning models that can identify toxicity in Online conversations, where toxicity is defined as <code>anything rude, disrespectful, or otherwise likely</code> to make someone leave the discussion. If these contributions can be identified, we could have a safer, more collaborative internet.</p>
</section>
<section id="dataset-description" class="level2">
<h2 class="anchored" data-anchor-id="dataset-description">Dataset Description</h2>
<p>As part of the competition, competitors were provided several files, specifically:</p>
<p><code>jigsaw-toxic-comment-train.csv</code> - data from the <a href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge">Jigsaw toxic comment classification competition</a>. The dataset is made up of English comments from Wikipedia’s talk page edits.</p>
<p><code>jigsaw-unintended-bias-train.csv</code> - data from the <a href="https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification">Jigsaw Unintended Bias in Toxicity Classification competition</a>. This is an expanded version of the Civil Comments dataset with a range of additional labels.</p>
<p><code>sample_submission.csv</code> - a sample submission file.</p>
<p><code>test.csv</code> - comments from Wikipedia talk pages in different non-English languages.</p>
<p><code>validation.csv</code> - comments from Wikipedia talk pages in different non-English languages</p>
</section>
<section id="evaluation-metric" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-metric">Evaluation Metric</h2>
<p>Submissions were evaluated based on Area Under the ROC Curve between the predicted probability and the observed target.</p>
</section>
<section id="strategies-to-tackle" class="level2">
<h2 class="anchored" data-anchor-id="strategies-to-tackle">Strategies to Tackle</h2>
<section id="monolingual-approach" class="level3">
<h3 class="anchored" data-anchor-id="monolingual-approach"><code>Monolingual Approach</code></h3>
<p>Monolingual models are the type of language models which are trained on a single language.</p>
<p>They are focused on understanding and generating text in a specific language.</p>
<p>For example, a monolingual model trained on English language will be proficient in understanding and generating English text.</p>
<p>These models are typically for tasks such as text classification, sentiment analysis and more within a specific language.</p>
<p>Monolingual models can be beneficial to utilize when we have a specific language in our training, testing datasets and in the upcoming unseen data.</p>
</section>
<section id="multilingual-approach" class="level3">
<h3 class="anchored" data-anchor-id="multilingual-approach"><code>Multilingual Approach</code></h3>
<p>Multilingual models are, on the other hand, are trained on multiple different languages.</p>
<p>They are designed to handle and process text in multiple languages, allowing them to perform across different languages.</p>
<p>Multilingual models have the advantage of of being able to provide language-agnostic solutions, as they can handle a wide-range of languages.</p>
<p>They can be used for zero-shot and few-shot learning, where the model can perform a task in a language it has not been seen specifically trained on by leveraging its knowledge of other languages.</p>
</section>
<section id="which-models-to-use-for-our-problem" class="level3">
<h3 class="anchored" data-anchor-id="which-models-to-use-for-our-problem"><code>Which models to use for our problem?</code></h3>
<p>As per the dataset given in the competition, we have only english data in our training dataset and very samples are given in the validation dataset containing languages <code>Spanish</code>, <code>Turkish</code> and <code>Italian</code> only and the Testing dataset contains languages <code>Turkish</code>, <code>Spanish</code>, <code>Italian</code>, <code>Russian</code>, <code>French</code> and <code>Portugese</code>.</p>
<p>Since in our validation and test dataset contains non-english languages it would be better approach to build multilingual models rather than monolingual models.</p>
<p>Now, if we had only one language (as stated above) building monolingual models would be a better choice.</p>
<p>Let’s discuss Multilingual models approach a bit more:</p>
<p>How are multilingual models are trained?</p>
<p>Multilingual models are pre-trained on a mix of different languages and they don’t distinguish between the languages.</p>
<p>The English BERT was pre-trained on English Wikipedia and BookCorpus dataset, while multilingual models like mBERT was pre-trained on 102 different languages from largest Wikipedia dataset and XLM-Roberta was pre-trained on CommonCrawl dataset from 100 different languages respectively.</p>
</section>
<section id="cross-lingual-transfer" class="level3">
<h3 class="anchored" data-anchor-id="cross-lingual-transfer"><code>Cross Lingual Transfer</code></h3>
<p>Cross-lingual transfer refers to transfer learning using data and models available for one language for which ample such resources are available (e.g., English) to solve tasks in another, commonly more low-resource, language.</p>
<p>In our case, we are trying to create an application that can automatically detect whether a sentence or phrase is toxic or not.</p>
<p>Models like XLM-Roberta provides us the ability to fine tune it on English dataset and predict to identify comments in any different language.</p>
<p>XLM-R is able to take it’s specific knowledge learnt in one language and apply it to a different langauge (languages), even though it never seen the language during fine-tuning.</p>
<p>This concept is of transfer learning applied from one language to another language is referred to as <code>Cross-Lingual Transfer (AKA Zero-Shot Learning)</code> .</p>
<p>Another reason to use Pre-Trained multi-lingual models for a task like this (as in our case) is that is the <code>Lack of languages by resources</code> i.e., different languages have different amounts of training data available to build models like BERT and its variants.</p>
<p>Some languages like English, Chinese, Russian, Indonesian, Vietnamese etc. are the languages that have high resource languages, whereas languages like sundanese, assamese etc. are low resource languages.</p>
<p>Training our own BERT like model on these low resources could be very expensive in terms of data collection and performance-wise , therefore, We should leverage these multi-lingual models.</p>
</section>
<section id="what-experiments-did-i-perform" class="level3">
<h3 class="anchored" data-anchor-id="what-experiments-did-i-perform"><code>What experiments did I perform ?</code></h3>
<p>At the Overall level, I performed 9 experiments with the following ideas keeping in mind.</p>
<p>Perform Pre-processing techniques like removal of stopwords, removing URLs, Contraction to Expansion of words, removing multiple characters from words and removal of punctuations.</p>
<p>From model stand point we experimented with 2 models mBERT &amp; XLM-Roberta.</p>
<p>From Training dataset perspective we used 2 types of datasets: one case where we used the provided training datasets where we tried to balance the dataset by the target and the other case where we used the translated training dataset of languages provided in the test dataset along with the english language with class balancing.</p>
<p>We always trained on validation dataset as well to further boost the performance of the model.</p>
<p>Now we build a model with the following ideas: &gt; Training on original training &amp; validation datasets, class balancing (undersampling), fine-tuning the model for 2 epochs on training as well as validation dataset, and will not perform any preprocessing dataset. We will be leveraging the TPUs offered by Kaggle.</p>
</section>
</section>
<section id="installing-libraries" class="level2">
<h2 class="anchored" data-anchor-id="installing-libraries">Installing Libraries</h2>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T07:22:33.408790Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T07:22:33.408138Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T07:23:35.810995Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T07:23:35.809930Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T07:22:33.408758Z&quot;}" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install nltk</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install transformers <span class="op">--</span>quiet</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, gc</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> TFAutoModel</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'stopwords'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Collecting nltk
  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 19.0 MB/s eta 0:00:0000:010:01
Requirement already satisfied: tqdm in /usr/local/lib/python3.8/site-packages (from nltk) (4.65.0)
Requirement already satisfied: click in /usr/local/lib/python3.8/site-packages (from nltk) (8.1.3)
Requirement already satisfied: joblib in /usr/local/lib/python3.8/site-packages (from nltk) (1.2.0)
Collecting regex&gt;=2021.8.3
  Downloading regex-2023.5.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 771.9/771.9 KB 38.4 MB/s eta 0:00:00
Installing collected packages: regex, nltk
Successfully installed nltk-3.8.1 regex-2023.5.5
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
WARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.
You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
WARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.
You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>True</code></pre>
</div>
</div>
</section>
<section id="setting-data-paths" class="level2">
<h2 class="anchored" data-anchor-id="setting-data-paths">Setting data paths</h2>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T07:23:35.813255Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T07:23:35.812749Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T07:23:35.818440Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T07:23:35.817610Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T07:23:35.813228Z&quot;}" data-execution_count="2">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>main_data_dir_path <span class="op">=</span> <span class="st">"../input/jigsaw-multilingual-toxic-comment-classification/"</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>toxic_comment_train_csv_path <span class="op">=</span> main_data_dir_path <span class="op">+</span> <span class="st">"jigsaw-toxic-comment-train.csv"</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>unintended_bias_train_csv_path <span class="op">=</span> main_data_dir_path <span class="op">+</span> <span class="st">"jigsaw-unintended-bias-train.csv"</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>validation_csv_path <span class="op">=</span> main_data_dir_path <span class="op">+</span> <span class="st">"validation.csv"</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>test_csv_path <span class="op">=</span> main_data_dir_path <span class="op">+</span> <span class="st">"test.csv"</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>submission_csv_path <span class="op">=</span> main_data_dir_path <span class="op">+</span> <span class="st">"sample_submission.csv"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="tpu-configurations" class="level2">
<h2 class="anchored" data-anchor-id="tpu-configurations">TPU Configurations</h2>
<p>Intializing the TPU configurations and other constants like <code>number of epochs, batch_size (16 * number of cores offered on TPUS), MAX_LEN (length of the sentence), we use xlm-roberta-large model, number of samples (for undersampling) = 150k, Learning_rate = 1e-5 etc.</code></p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T07:23:38.288496Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T07:23:38.288089Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T07:23:47.572679Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T07:23:47.571505Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T07:23:38.288467Z&quot;}" data-jupyter="{&quot;outputs_hidden&quot;:true}" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#################### TPU Configurations ####################</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Detect hardware, return appropriate distribution strategy</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># TPU detection. No parameters necessary if TPU_NAME environment variable is</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set: this is always the case on Kaggle.</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    tpu <span class="op">=</span> tf.distribute.cluster_resolver.TPUClusterResolver()</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Running on TPU '</span>, tpu.master())</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ValueError</span>:</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    tpu <span class="op">=</span> <span class="va">None</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> tpu:</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    tf.config.experimental_connect_to_cluster(tpu)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    tf.tpu.experimental.initialize_tpu_system(tpu)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    strategy <span class="op">=</span> tf.distribute.TPUStrategy(tpu)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Default distribution strategy in Tensorflow. Works on CPU and single GPU.</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    strategy <span class="op">=</span> tf.distribute.get_strategy()</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"REPLICAS: "</span>, strategy.num_replicas_in_sync)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>AUTO <span class="op">=</span> tf.data.experimental.AUTOTUNE</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>EPOCHS <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">16</span> <span class="op">*</span> strategy.num_replicas_in_sync</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>MAX_LEN <span class="op">=</span> <span class="dv">192</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>MODEL <span class="op">=</span> <span class="st">'xlm-roberta-large'</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>NUM_SAMPLES <span class="op">=</span> <span class="dv">150000</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>RANDOM_STATE <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>LEARNING_RATE <span class="op">=</span> <span class="fl">1e-5</span> <span class="co">######################### MAIN CHANGE ############################</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>WEIGHT_DECAY <span class="op">=</span> <span class="fl">1e-6</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running on TPU  
INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.
INFO:tensorflow:Initializing the TPU system: local
INFO:tensorflow:Finished initializing TPU system.
INFO:tensorflow:Found TPU system:
INFO:tensorflow:*** Num TPU Cores: 8
INFO:tensorflow:*** Num TPU Workers: 1
INFO:tensorflow:*** Num TPU Cores Per Worker: 8
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
REPLICAS:  8</code></pre>
</div>
</div>
</section>
<section id="reading-balancing-the-data-by-target-column" class="level2">
<h2 class="anchored" data-anchor-id="reading-balancing-the-data-by-target-column">Reading &amp; Balancing the data by Target column</h2>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T07:23:47.574865Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T07:23:47.574503Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T07:24:17.487288Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T07:24:17.485969Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T07:23:47.574836Z&quot;}" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Reading csv files </span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>train1 <span class="op">=</span> pd.read_csv(toxic_comment_train_csv_path)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>train2 <span class="op">=</span> pd.read_csv(unintended_bias_train_csv_path)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>valid <span class="op">=</span> pd.read_csv(validation_csv_path)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> pd.read_csv(test_csv_path)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>sub <span class="op">=</span> pd.read_csv(submission_csv_path)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co">## Converting floating points to integers ##</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>train2.toxic <span class="op">=</span> train2[<span class="st">'toxic'</span>].<span class="bu">round</span>().astype(<span class="bu">int</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">##### BALANCING THE DATA ##### </span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co"># : Taking all the data from toxic_comment_train_file &amp; all data corresponding to unintended bias train file</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co"># &amp; sampling 150k observations randomly from non-toxic observation population.</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine train1 with a subset of train2</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> pd.concat([</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    train1[[<span class="st">'comment_text'</span>, <span class="st">'toxic'</span>]],</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    train2[[<span class="st">'comment_text'</span>, <span class="st">'toxic'</span>]].query(<span class="st">'toxic==1'</span>),</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    train2[[<span class="st">'comment_text'</span>, <span class="st">'toxic'</span>]].query(<span class="st">'toxic==0'</span>).sample(n<span class="op">=</span>NUM_SAMPLES, random_state<span class="op">=</span>RANDOM_STATE)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="co">## Dropping missing observations with respect to comment-text column </span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> train.dropna(subset<span class="op">=</span>[<span class="st">'comment_text'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T07:24:19.248281Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T07:24:19.247827Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T07:24:19.255160Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T07:24:19.254028Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T07:24:19.248249Z&quot;}" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> encode(texts, tokenizer, max_len):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Function takes a list of texts, tokenizer (object)</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">    initialized from HuggingFace library, max_len (defines</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">    of how long the sentence lengths should be).</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span>       </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> tokenizer(texts, max_length<span class="op">=</span>max_len, </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>                    truncation<span class="op">=</span><span class="va">True</span>, padding<span class="op">=</span><span class="st">'max_length'</span>,</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>                    add_special_tokens<span class="op">=</span><span class="va">True</span>, return_tensors<span class="op">=</span><span class="st">'np'</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tokens</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="encoding-comment_text" class="level2">
<h2 class="anchored" data-anchor-id="encoding-comment_text">Encoding comment_text</h2>
<p>We first initialize the tokenizer from Hugging Face transformer library and encoding our training, validation and test dataset comment_texts.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T07:24:20.808760Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T07:24:20.807724Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T07:25:17.700276Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T07:25:17.698933Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T07:24:20.808723Z&quot;}" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Intializing the tokenizer ##</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(MODEL)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>train_inputs <span class="op">=</span> encode(train[<span class="st">'comment_text'</span>].values.tolist(), </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>                      tokenizer, max_len<span class="op">=</span>MAX_LEN)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>validation_inputs <span class="op">=</span> encode(valid[<span class="st">'comment_text'</span>].values.tolist(),</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>                          tokenizer, max_len<span class="op">=</span>MAX_LEN)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>test_inputs <span class="op">=</span> encode(test[<span class="st">'content'</span>].values.tolist(),</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>                    tokenizer, max_len<span class="op">=</span>MAX_LEN)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="preparing-data-using-tf.data.data-api" class="level2">
<h2 class="anchored" data-anchor-id="preparing-data-using-tf.data.data-api">Preparing data using tf.data.Data API</h2>
<p>Writing a function to create a tuple of inputs and outputs, where inputs have a dictionary datatype.</p>
<p>We’ll be leveraging tf.data.Data API to pass our inputs and outputs as tuple, i.e., (inputs, outputs), inputs are <code>{"input_ids": input_ids, "attention_mask": attention_mask} and outputs labels</code>.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T07:25:20.108817Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T07:25:20.108341Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T07:25:20.114569Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T07:25:20.113537Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T07:25:20.108784Z&quot;}" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> map_fn(input_ids, attention_mask, labels<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> labels <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">"input_ids"</span>: input_ids, <span class="st">"attention_mask"</span>: attention_mask}, labels</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">"input_ids"</span>: input_ids, <span class="st">"attention_mask"</span>: attention_mask}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T07:25:21.211292Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T07:25:21.210320Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T07:25:22.088206Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T07:25:22.087132Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T07:25:21.211257Z&quot;}" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((train_inputs[<span class="st">"input_ids"</span>],</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>                                                    train_inputs[<span class="st">"attention_mask"</span>],</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>                                                   train[<span class="st">'toxic'</span>]))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> train_dataset.<span class="bu">map</span>(map_fn)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> train_dataset.repeat().shuffle(buffer_size<span class="op">=</span><span class="dv">2048</span>,seed<span class="op">=</span>RANDOM_STATE).batch(BATCH_SIZE).prefetch(AUTO)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>validation_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((validation_inputs[<span class="st">'input_ids'</span>],</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>                                                         validation_inputs[<span class="st">'attention_mask'</span>],</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>                                                        valid[<span class="st">'toxic'</span>]))</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>validation_dataset <span class="op">=</span> validation_dataset.<span class="bu">map</span>(map_fn)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>validation_dataset <span class="op">=</span> validation_dataset.batch(BATCH_SIZE).prefetch(AUTO)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((test_inputs[<span class="st">'input_ids'</span>],</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>                                                  test_inputs[<span class="st">'attention_mask'</span>]))</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> test_dataset.<span class="bu">map</span>(map_fn)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> test_dataset.batch(BATCH_SIZE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="building-the-model" class="level2">
<h2 class="anchored" data-anchor-id="building-the-model">Building the model</h2>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T07:25:24.088859Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T07:25:24.087623Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T07:25:24.098396Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T07:25:24.097425Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T07:25:24.088820Z&quot;}" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_model(transformer_layer, max_len):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Creating the model input layers, output layers,</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co">    model definition and compilation.</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns: model object after compiling. </span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    input_ids <span class="op">=</span> tf.keras.layers.Input(shape<span class="op">=</span>(max_len,), </span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>                                      dtype<span class="op">=</span>tf.int32, </span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>                                      name<span class="op">=</span><span class="st">"input_ids"</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    attention_mask <span class="op">=</span> tf.keras.layers.Input(shape<span class="op">=</span>(max_len,), </span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>                                       dtype<span class="op">=</span>tf.int32, </span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>                                       name<span class="op">=</span><span class="st">"attention_mask"</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> transformer_layer.roberta(input_ids, </span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>                                 attention_mask<span class="op">=</span>attention_mask)[<span class="dv">1</span>]</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">1024</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(output)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> tf.keras.layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>,name<span class="op">=</span><span class="st">'outputs'</span>)(x)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> tf.keras.models.Model(inputs<span class="op">=</span>[input_ids, attention_mask],</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>                             outputs<span class="op">=</span>y)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> tf.keras.optimizers.Adam(learning_rate<span class="op">=</span>LEARNING_RATE,</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>                                         weight_decay<span class="op">=</span>WEIGHT_DECAY)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> tf.keras.losses.BinaryCrossentropy()</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>    AUC <span class="op">=</span> tf.keras.metrics.AUC()</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(loss<span class="op">=</span>loss, metrics<span class="op">=</span>[AUC], optimizer<span class="op">=</span>optimizer)    </span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="loading-model-on-tpus" class="level2">
<h2 class="anchored" data-anchor-id="loading-model-on-tpus">Loading model on TPUs</h2>
<p>It is important to initialize &amp; compile the model inside the <code>with strategy.scope()</code>.</p>
<p>One thing I want to point out that for some reason I was getting different results even though I was setting the seed before initializing the model, but the results are always consistent even though the results differ very little every time we run the pipeline.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T07:25:26.128412Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T07:25:26.127843Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T07:27:20.756174Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T07:27:20.754801Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T07:25:26.128375Z&quot;}" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> strategy.scope():</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    transformer_layer <span class="op">=</span> TFAutoModel.from_pretrained(MODEL)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    tf.random.set_seed(RANDOM_STATE)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> build_model(transformer_layer,</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>                        max_len<span class="op">=</span>MAX_LEN)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_ids (InputLayer)         [(None, 192)]        0           []                               
                                                                                                  
 attention_mask (InputLayer)    [(None, 192)]        0           []                               
                                                                                                  
 roberta (TFXLMRobertaMainLayer  TFBaseModelOutputWi  559890432  ['input_ids[0][0]',              
 )                              thPoolingAndCrossAt               'attention_mask[0][0]']         
                                tentions(last_hidde                                               
                                n_state=(None, 192,                                               
                                 1024),                                                           
                                 pooler_output=(Non                                               
                                e, 1024),                                                         
                                 past_key_values=No                                               
                                ne, hidden_states=N                                               
                                one, attentions=Non                                               
                                e, cross_attentions                                               
                                =None)                                                            
                                                                                                  
 dense (Dense)                  (None, 1024)         1049600     ['roberta[0][1]']                
                                                                                                  
 outputs (Dense)                (None, 1)            1025        ['dense[0][0]']                  
                                                                                                  
==================================================================================================
Total params: 560,941,057
Trainable params: 560,941,057
Non-trainable params: 0
__________________________________________________________________________________________________</code></pre>
</div>
</div>
</section>
<section id="training-the-model-on-only-english-data-for-2-epochs" class="level2">
<h2 class="anchored" data-anchor-id="training-the-model-on-only-english-data-for-2-epochs">Training the model on Only English data for 2 epochs</h2>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T07:27:22.298147Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T07:27:22.297769Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T08:17:33.238761Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T08:17:33.237230Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T07:27:22.298116Z&quot;}" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>train_steps_per_epoch <span class="op">=</span> train_inputs[<span class="st">'input_ids'</span>].shape[<span class="dv">0</span>] <span class="op">//</span> BATCH_SIZE</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>train_history <span class="op">=</span> model.fit(train_dataset,</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>                         steps_per_epoch<span class="op">=</span>train_steps_per_epoch,</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>                         validation_data<span class="op">=</span>validation_dataset,</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>                         epochs<span class="op">=</span><span class="dv">2</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/2
3795/3795 [==============================] - ETA: 0s - loss: 0.0551 - auc: 0.99703795/3795 [==============================] - 1609s 378ms/step - loss: 0.0551 - auc: 0.9970 - val_loss: 0.4696 - val_auc: 0.8942
Epoch 2/2
3795/3795 [==============================] - 1399s 369ms/step - loss: 0.0450 - auc: 0.9979 - val_loss: 0.3125 - val_auc: 0.9083</code></pre>
</div>
</div>
</section>
<section id="training-the-model-on-validation-data-for-2-epochs-further-to-fine-tune-on-it" class="level2">
<h2 class="anchored" data-anchor-id="training-the-model-on-validation-data-for-2-epochs-further-to-fine-tune-on-it">Training the model on Validation data for 2 epochs further to fine-tune on it</h2>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T08:17:39.839805Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T08:17:39.839062Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T08:19:50.565792Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T08:19:50.564151Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T08:17:39.839770Z&quot;}" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>validation_steps_per_epoch <span class="op">=</span> validation_inputs[<span class="st">'input_ids'</span>].shape[<span class="dv">0</span>] <span class="op">//</span> BATCH_SIZE</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>validation_history <span class="op">=</span> model.fit(validation_dataset.repeat(),</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>                              steps_per_epoch<span class="op">=</span>validation_steps_per_epoch,</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>                              epochs<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/2
62/62 [==============================] - 23s 367ms/step - loss: 0.2286 - auc: 0.9315
Epoch 2/2
62/62 [==============================] - 107s 365ms/step - loss: 0.1472 - auc: 0.9726</code></pre>
</div>
</div>
<ul>
<li>Public LeaderBoard score on kaggle (test dataset): 0.936 and Private LeaderBoard score : 0.9346</li>
</ul>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Experiment</th>
<th>Public Test LeaderBoard Score</th>
<th>Private Test LeaderBoard Score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1 (mBERT + No Preprocessing + BCE Loss + Fine tune on original training and validation datasets for 2 epochs each + Learning_rate = 2e-5)</td>
<td>0.8850</td>
<td>0.8869</td>
</tr>
<tr class="even">
<td>2 (xlm-roberta-large + No Preprocessing + BCE Loss + Fine tune on original training and validation datasets for 2 epochs each + Learning_rate = 2e-5)</td>
<td>0.9259</td>
<td>0.9264</td>
</tr>
<tr class="odd">
<td>3 (mBERT + Preprocessing + BCE Loss + Fine tune on original training and validation datasets for 2 epochs each + Learning_rate = 2e-5)</td>
<td>0.8259</td>
<td>0.8239</td>
</tr>
<tr class="even">
<td>4 (xlm-roberta-large + Preprocessing + BCE Loss + Fine tune on original training and validation datasets for 2 epochs each + Learning_rate = 2e-5)</td>
<td>0.8755</td>
<td>0.8754</td>
</tr>
<tr class="odd">
<td>5 (mBERT + No Preprocessing + BCE Loss + Fine tune on translated in languages present in test (along with english original english) training and validation datasets for 2 epochs each + Learning_rate = 1e-5)</td>
<td>0.9195</td>
<td>0.9212</td>
</tr>
<tr class="even">
<td>6 ((xlm-roberta-large + No Preprocessing + BCE Loss + Fine tune on translated in languages present in test (along with english original english) training and validation datasets for 2 epochs each + Learning_rate = 1e-5)</td>
<td>0.9329</td>
<td>0.9212</td>
</tr>
<tr class="odd">
<td>7 (mBERT + Preprocessing + BCE Loss + Fine tune on translated in languages present in test (along with english original english) training and validation datasets for 2 epochs each + Learning_rate = 1e-5)</td>
<td>0.8696</td>
<td>0.9212</td>
</tr>
<tr class="even">
<td>8 ((xlm-roberta-large + Preprocessing + BCE Loss + Fine tune on translated in languages present in test (along with english original english) training and validation datasets for 2 epochs each + Learning_rate = 1e-5)</td>
<td>0.8861</td>
<td>0.8866</td>
</tr>
<tr class="odd">
<td>9 (xlm-roberta-large + No Preprocessing + BCE Loss + Fine tune on original training and validation datasets for 2 epochs each + Learning_rate = 1e-5)</td>
<td>0.936</td>
<td>0.9346</td>
</tr>
</tbody>
</table>
</section>
<section id="predicting-on-test-dataset" class="level2">
<h2 class="anchored" data-anchor-id="predicting-on-test-dataset">Predicting on Test dataset</h2>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T08:19:55.118899Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T08:19:55.118459Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T08:21:15.297689Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T08:21:15.296342Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T08:19:55.118866Z&quot;}" data-execution_count="13">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>sub[<span class="st">'toxic'</span>] <span class="op">=</span> model.predict(test_dataset, verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>sub.to_csv(<span class="st">'submission.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>499/499 [==============================] - 80s 119ms/step</code></pre>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T08:21:53.414762Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T08:21:53.414255Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T08:21:53.429904Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T08:21:53.428621Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T08:21:53.414725Z&quot;}" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>sub.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">toxic</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>0.000308</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>0.000241</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2</td>
<td>0.266148</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>3</td>
<td>0.000063</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>4</td>
<td>0.000078</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="saving-the-model" class="level2">
<h2 class="anchored" data-anchor-id="saving-the-model">Saving the model</h2>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T08:21:57.599260Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T08:21:57.598292Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T08:23:19.245054Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T08:23:19.243642Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T08:21:57.599220Z&quot;}" data-execution_count="15">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>model_save_path <span class="op">=</span> <span class="st">"../working/Multilingual_toxic_comment_classifier"</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>model.save(model_save_path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO:tensorflow:Assets written to: ../working/Multilingual_toxic_comment_classifier/assets</code></pre>
</div>
</div>
</section>
<section id="loading-the-model" class="level2">
<h2 class="anchored" data-anchor-id="loading-the-model">Loading the model</h2>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T08:23:25.622630Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T08:23:25.622191Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T08:24:35.677429Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T08:24:35.676025Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T08:23:25.622576Z&quot;}" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>model_save_path <span class="op">=</span> <span class="st">"../working/Multilingual_toxic_comment_classifier"</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>loaded_model <span class="op">=</span> tf.keras.models.load_model(model_save_path)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> loaded_model.predict(test_dataset.take(<span class="dv">1</span>))</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>y[:<span class="dv">6</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 37s 37s/step</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>array([[3.0799874e-04],
       [2.2472920e-04],
       [2.6646560e-01],
       [5.7183450e-05],
       [7.6287179e-05],
       [3.1223629e-02]], dtype=float32)</code></pre>
</div>
</div>
<p>Writing the function to prepare for the new text, we encode the text using the <code>tokenizer with the sentence length=192</code></p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T08:24:42.590889Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T08:24:42.589669Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T08:24:43.396330Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T08:24:43.394865Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T08:24:42.590852Z&quot;}" data-execution_count="17">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>tokenizer_ <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"xlm-roberta-large"</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"politicians are like cancer for this country"</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prep_data(text, tokenizer, max_len<span class="op">=</span><span class="dv">192</span>):</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> tokenizer(text, max_length<span class="op">=</span>max_len, </span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>                    truncation<span class="op">=</span><span class="va">True</span>, padding<span class="op">=</span><span class="st">'max_length'</span>,</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>                    add_special_tokens<span class="op">=</span><span class="va">True</span>, return_tensors<span class="op">=</span><span class="st">'tf'</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"input_ids"</span>: tokens[<span class="st">'input_ids'</span>],</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>            <span class="st">"attention_mask"</span>: tokens[<span class="st">'attention_mask'</span>]}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Predicting the probability of toxic and non-toxic on a sample text.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T08:24:46.139977Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T08:24:46.138911Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T08:24:55.313920Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T08:24:55.312636Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T08:24:46.139939Z&quot;}" data-execution_count="18">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>prob_of_toxic_comment <span class="op">=</span> loaded_model.predict(prep_data(text<span class="op">=</span>text, tokenizer<span class="op">=</span>tokenizer_, max_len<span class="op">=</span><span class="dv">192</span>))[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>prob_of_non_toxic_comment <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> prob_of_toxic_comment</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>prob_of_toxic_comment, prob_of_non_toxic_comment</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> {<span class="st">"prob_of_toxic_comment"</span>: prob_of_toxic_comment,</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a> <span class="st">"prob_of_non_toxic_comment"</span>: prob_of_non_toxic_comment}</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>probs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1/1 [==============================] - 9s 9s/step</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>{'prob_of_toxic_comment': 0.26497197,
 'prob_of_non_toxic_comment': 0.7350280284881592}</code></pre>
</div>
</div>
<section id="testing-the-model-with-the-gradio-app-before-final-pushing-the-model-to-huggingface-spaces" class="level3">
<h3 class="anchored" data-anchor-id="testing-the-model-with-the-gradio-app-before-final-pushing-the-model-to-huggingface-spaces">Testing the model with the Gradio App before final pushing the model to HuggingFace Spaces</h3>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-05-08T09:10:07.958578Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-05-08T09:10:07.958160Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-05-08T09:10:59.295870Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-05-08T09:10:59.294407Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-05-08T09:10:07.958550Z&quot;}" data-execution_count="28">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip3 install gradio <span class="op">--</span>quiet</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>loaded_model <span class="op">=</span> tf.keras.models.load_model(model_save_path)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>tokenizer_ <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"xlm-roberta-large"</span>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>examples_list <span class="op">=</span> [<span class="st">"politicians are like cancer for this country"</span>, </span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было,"</span>,</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Для каких стан является эталоном современная система здравоохранения РФ? Для Зимбабве? Ты тупой? хох"</span>,</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prep_data(text, tokenizer, max_len<span class="op">=</span><span class="dv">192</span>):</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> tokenizer(text, max_length<span class="op">=</span>max_len, </span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>                    truncation<span class="op">=</span><span class="va">True</span>, padding<span class="op">=</span><span class="st">'max_length'</span>,</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>                    add_special_tokens<span class="op">=</span><span class="va">True</span>, return_tensors<span class="op">=</span><span class="st">'tf'</span>)</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"input_ids"</span>: tokens[<span class="st">'input_ids'</span>],</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>            <span class="st">"attention_mask"</span>: tokens[<span class="st">'attention_mask'</span>]}</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(text):</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>    prob_of_toxic_comment <span class="op">=</span> loaded_model.predict(prep_data(text<span class="op">=</span>text, tokenizer<span class="op">=</span>tokenizer_, max_len<span class="op">=</span><span class="dv">192</span>))[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>    prob_of_non_toxic_comment <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> prob_of_toxic_comment</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>    prob_of_toxic_comment, prob_of_non_toxic_comment</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>    probs <span class="op">=</span> {<span class="st">"prob_of_toxic_comment"</span>: <span class="bu">float</span>(prob_of_toxic_comment),</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>             <span class="st">"prob_of_non_toxic_comment"</span>: <span class="bu">float</span>(prob_of_non_toxic_comment)}</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> probs</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>interface <span class="op">=</span> gr.Interface(fn<span class="op">=</span>predict, inputs<span class="op">=</span>gr.components.Textbox(lines<span class="op">=</span><span class="dv">4</span>,label<span class="op">=</span><span class="st">'Comment'</span>),</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>                        outputs<span class="op">=</span>[gr.Label(label<span class="op">=</span><span class="st">'Probabilities'</span>)], examples<span class="op">=</span>examples_list,</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>                        title<span class="op">=</span><span class="st">'Multi-Lingual Toxic Comment Classification.'</span>,</span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>                        description<span class="op">=</span><span class="st">'XLM-Roberta Large model'</span>)</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>interface.launch(debug<span class="op">=</span><span class="va">False</span>, share<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
WARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.
You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.
Running on local URL:  http://127.0.0.1:7865
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Running on public URL: https://af370decb4339b429e.gradio.live

This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces
1/1 [==============================] - 8s 8s/step
1/1 [==============================] - 1s 530ms/step
1/1 [==============================] - 1s 513ms/step</code></pre>
</div>
<div class="cell-output cell-output-display">
<div><iframe src="https://af370decb4339b429e.gradio.live" width="100%" height="500" allow="autoplay; camera; microphone; clipboard-read; clipboard-write;" frameborder="0" allowfullscreen=""></iframe></div>
</div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code></code></pre>
</div>
</div>
<p>Woow!!!</p>
<p>Our application is up and running, this link is only temporary and and it remains ony for 72 hours. For permanent hosting, we can upload our Gradio app Interface to <a href="https://huggingface.co/spaces">HuggingFace Spaces</a>.</p>
<p>Now download all the files and folders from kaggle output manually &amp; this kaggle kernel locally</p>
</section>
</section>
<section id="turning-our-multi-lingual-toxic-comment-classification-gradio-demo-into-a-deployable-app" class="level2">
<h2 class="anchored" data-anchor-id="turning-our-multi-lingual-toxic-comment-classification-gradio-demo-into-a-deployable-app">Turning our Multi-Lingual Toxic Comment Classification Gradio Demo into a deployable app</h2>
<p>We’ll deploy the demo application on HuggingFace Spaces.</p>
<p>What is HuggingFace Spaces?</p>
<p>It is a resource that allows anybody to host and share machine learning application.</p>
<section id="deployed-gradio-app-structure" class="level3">
<h3 class="anchored" data-anchor-id="deployed-gradio-app-structure">Deployed Gradio App Structure</h3>
<p>To upload our gradio app, we’ll want to put everything together into a singe directory.</p>
<p>For example, our demo might live at the path <code>demos/melanoma_skin_cancer_files</code> with the following structure:</p>
<pre><code>demos/
    └── multilingual_toxic_comment_files/
        ├── Multilingual_toxic_comment_classifier/
        │   ├── variable/
        │   │   ├── variables.data-00000-of-00001
        │   │   └── variables.index
        │   ├── fingerprint.pb
        │   ├── keras_metadata.pb
        │   └── saved_model.pb 
        ├── app.py
        ├── examples/
        │   └── dataset
        └── requirements.txt</code></pre>
<p>Where: - <code>Multilingual_toxic_comment_classifier</code> is our saved fine-tuned model (binary files associated). - <code>app.py</code> contains our Gradio app, our data preprocessing function and our predict function. <strong>Note</strong>: <code>app.py</code> is the default filename used for HuggingFace Spaces, if we deploy our apps there. - <code>examples</code> contains sample dataframe which contains toxic &amp; non-toxic comments from russian, spanish, english, italian, turkish, portugese and last french languages to showcase the demo of our Gradio application. - <code>requirements.txt</code> file contains the dependencies/packages to run our application such as tensorflow, gradio, transformers.</p>
</section>
<section id="creating-a-demo-folder-to-store-our-multilingual-toxic-comment-classifier-app-files" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-demo-folder-to-store-our-multilingual-toxic-comment-classifier-app-files">Creating a demo folder to store our Multilingual Toxic Comment Classifier App files</h3>
<p>To begin, we’ll create an empty directory <code>demos/</code> that will contain all our necessary files for the application.</p>
<p>We can achive this using Python’s <code>pathlib.Path("path_of_dir")</code> to establish directory path and then <code>pathlib.Path("path_of_dir").mkdir()</code> to create it.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co">############### ROOT_DIR : I Have put the files in my E: drive</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co">## Importing Packages </span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>ROOT_DIR <span class="op">=</span> <span class="st">"</span><span class="ch">\\</span><span class="st">"</span>.join(os.getcwd().split(<span class="st">"</span><span class="ch">\\</span><span class="st">"</span>)[:<span class="dv">2</span>])</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="co">## Create Melanoma skin cancer demo path</span></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>multilingual_toxic_comment_demo_path <span class="op">=</span> Path(<span class="ss">f"</span><span class="sc">{</span>ROOT_DIR<span class="sc">}</span><span class="ss">/demos/multilingual_toxic_comment_files"</span>)</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a><span class="co">## Removing files that might already exist and creating a new directory.</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> multilingual_toxic_comment_demo_path.exists():</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>    shutil.rmtree(multilingual_toxic_comment_demo_path)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    multilingual_toxic_comment_demo_path.mkdir(parents<span class="op">=</span><span class="va">True</span>, <span class="co"># Do we want to make parent folders?</span></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>                                exist_ok<span class="op">=</span><span class="va">True</span>) <span class="co"># Create even if they already exists? </span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">## If the path doesn't exist, create one </span></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>    multilingual_toxic_comment_demo_path.mkdir(parents<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>                                exist_ok<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="creating-a-folder-of-example-images-to-use-with-our-melanoma-skin-cancer-demo" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-folder-of-example-images-to-use-with-our-melanoma-skin-cancer-demo">Creating a folder of example images to use with our Melanoma skin cancer demo</h3>
<p>Now we’ll create an empty directory called <code>examples</code> and store a sample dataset containing comments from the Russian, Turkish, English, Spanish, Portugese, French, Italian languages. I have collected these comments from online and created a CSV file for them.</p>
<p>To do so we’ll:</p>
<ol type="1">
<li>Create an empty directory <code>examples/</code> within the <code>demos/multilingual_toxic_comment_files</code> directory.</li>
<li>Collect some comment samples from online in these languages and create a CSV file out of them containing both toxic as well as non-toxic comments.</li>
</ol>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co">## Create examples directory</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>multilingual_toxic_comment_examples_path <span class="op">=</span> multilingual_toxic_comment_demo_path <span class="op">/</span> <span class="st">"examples"</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>multilingual_toxic_comment_examples_path.mkdir(parents<span class="op">=</span><span class="va">True</span>, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>sample_comments <span class="op">=</span> Path(<span class="ss">f"sample_comments.csv"</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>comments <span class="op">=</span> {<span class="st">"comment_text"</span>: [<span class="st">"Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал."</span>,</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?"</span>,</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"В шапке были ссылки на инфу по текущему фильму марвел. Эти ссылки были заменены на фразу Репортим брипидора, игнорируем его посты. Если этого недостаточно, чтобы понять, что модератор абсолютный неадекват, и его нужно лишить полномочий, тогда эта борда пробивает абсолютное дно по неадекватности."</span>,</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"Про графику было обидно) я так то проходил все серии гта со второй части по пятую, кроме гта 4. И мне не мешала графика ни в одной из частей. На компе у меня было куча видеокарт. Начиная с 32мб RIVA TNT и заканчивая 2Гб 560Ti на которой я спокойно играю который год в танки, гта5, ведьмака3 купил на распродаже и начал проходить. Да, не на ультрах. С пониженными текстурами. И не мешает. Я не понимаю дрочева на графике, требовать графику уровня плойки 4 минимум. Мне надо чтобы глаза не резало, только и всего. По поводу управления, мне не хватает переходника на type c. У меня джойстик есть от иксбокса360. Потенциала в мобильных играх достаточно чтобы забить кнопки как забивались в той же NFS MW в 2005. Не самая плохая игра была."</span>,</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"This is such an urgent design problem; kudos to you for taking it on. Very impressive!"</span>,</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"haha you guys are a bunch of losers."</span>, <span class="st">"ur a sh*tty comment."</span>,</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"Il solito vizio,o moda, della sinistra di andare ad aiutare tutti tranne chi ne ha bisogno in casa nostra. Quanti autorespiratori si sarebbero potuti acquistare con 50 milioni di euro? Bastardi traditori della patria!!"</span>,</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>                 <span class="st">'SIAMO ALLA FOLLIA'</span>, </span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>                 <span class="st">'20px Caro editor, encontramos problemas na edição que fez na página Sertanejo universitário. A edição teve de ser revertida por não ser adequada para a Wikipédia. Se quiser experimentar a edição de páginas pode fazê-lo à vontade na página de testes da Wikipédia. Recomenda-se a leitura das páginas Breve introdução sobre a Wikipédia, O que a Wikipédia não é e Erros comuns na Wikipédia. Obrigado pela compreensão.    Vitor       Mazuco    Msg '</span>,</span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"Le contributeur  y  tente de prouver par l absurde que le commentaire de diff du contributeur  x  est ridicule en recopiant ce dernier, et supprime sans autre explication un passage apparemment parfaitement consensuel. Qui plus est, le contributeur  y  ne prend pas la peine de discuter de la précédente contribution du contributeur  x , alors que l article a déjà un bandeau d avertissement à ne pas se lancer dans des guerres d édition. Bref, la prochaine fois, je vous bloque pour désorganisation du projet en vue d une argumentation personnelle. L article est déjà assez instable pour que vous n y mêliez pas une guerre d ego - et si vous n aimez pas qu on vous rappelle de ne pas  jouer au con , qui n est en rien une insulte, mais la détection d un problème de comportement, n y jouez pas. SammyDay (discuter) "</span>]}</span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(comments, </span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>             columns<span class="op">=</span>[<span class="st">'comment_text'</span>]).to_csv(multilingual_toxic_comment_examples_path <span class="op">/</span> sample_comments,</span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>                                              index<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we verify our example images are present, let’s list the contents of our <code>demo/melanoma_skin_cancer/examples/</code> directory with <code>os.listdir()</code> and then format the filepaths into a list of lists (to make it compatible with the Gradio’s <code>gradio.Interface()</code>, example parameter).</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>example_list <span class="op">=</span> [[example] <span class="cf">for</span> example <span class="kw">in</span> pd.read_csv(multilingual_toxic_comment_examples_path <span class="op">/</span> sample_comments)[<span class="st">'comment_text'</span>].tolist()]</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>example_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>[['Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.'],
 ['Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?'],
 ['В шапке были ссылки на инфу по текущему фильму марвел. Эти ссылки были заменены на фразу Репортим брипидора, игнорируем его посты. Если этого недостаточно, чтобы понять, что модератор абсолютный неадекват, и его нужно лишить полномочий, тогда эта борда пробивает абсолютное дно по неадекватности.'],
 ['Про графику было обидно) я так то проходил все серии гта со второй части по пятую, кроме гта 4. И мне не мешала графика ни в одной из частей. На компе у меня было куча видеокарт. Начиная с 32мб RIVA TNT и заканчивая 2Гб 560Ti на которой я спокойно играю который год в танки, гта5, ведьмака3 купил на распродаже и начал проходить. Да, не на ультрах. С пониженными текстурами. И не мешает. Я не понимаю дрочева на графике, требовать графику уровня плойки 4 минимум. Мне надо чтобы глаза не резало, только и всего. По поводу управления, мне не хватает переходника на type c. У меня джойстик есть от иксбокса360. Потенциала в мобильных играх достаточно чтобы забить кнопки как забивались в той же NFS MW в 2005. Не самая плохая игра была.'],
 ['This is such an urgent design problem; kudos to you for taking it on. Very impressive!'],
 ['haha you guys are a bunch of losers.'],
 ['ur a sh*tty comment.'],
 ['Il solito vizio,o moda, della sinistra di andare ad aiutare tutti tranne chi ne ha bisogno in casa nostra. Quanti autorespiratori si sarebbero potuti acquistare con 50 milioni di euro? Bastardi traditori della patria!!'],
 ['SIAMO ALLA FOLLIA'],
 ['20px Caro editor, encontramos problemas na edição que fez na página Sertanejo universitário. A edição teve de ser revertida por não ser adequada para a Wikipédia. Se quiser experimentar a edição de páginas pode fazê-lo à vontade na página de testes da Wikipédia. Recomenda-se a leitura das páginas Breve introdução sobre a Wikipédia, O que a Wikipédia não é e Erros comuns na Wikipédia. Obrigado pela compreensão.    Vitor       Mazuco    Msg '],
 ['Le contributeur  y  tente de prouver par l absurde que le commentaire de diff du contributeur  x  est ridicule en recopiant ce dernier, et supprime sans autre explication un passage apparemment parfaitement consensuel. Qui plus est, le contributeur  y  ne prend pas la peine de discuter de la précédente contribution du contributeur  x , alors que l article a déjà un bandeau d avertissement à ne pas se lancer dans des guerres d édition. Bref, la prochaine fois, je vous bloque pour désorganisation du projet en vue d une argumentation personnelle. L article est déjà assez instable pour que vous n y mêliez pas une guerre d ego - et si vous n aimez pas qu on vous rappelle de ne pas  jouer au con , qui n est en rien une insulte, mais la détection d un problème de comportement, n y jouez pas. SammyDay (discuter) ']]</code></pre>
</div>
</div>
</section>
<section id="moving-our-trained-xlm-roberta-model-binary-files-into-our-multilingual_toxic_comment_files-demo-directory." class="level3">
<h3 class="anchored" data-anchor-id="moving-our-trained-xlm-roberta-model-binary-files-into-our-multilingual_toxic_comment_files-demo-directory.">Moving our trained XLM-Roberta model binary files into our multilingual_toxic_comment_files demo directory.</h3>
<p>We have saved our fine-tuned model in <code>outout/working/multilingual_toxic_comment_files/</code> directory and we’ll move our model files to <code>demos/multilingual_toxic_comment_files/</code> directory as specified above.</p>
<p>We use Python’s <code>shutil.move()</code> method and passing in <code>src</code>(the source path of the target file) and <code>dst</code> (the destination folder path of the target file to be moved into) parameters.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Importing Libraries</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co">## Create a source path for our target model</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>multilingual_toxic_comment_model_dir_path <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>ROOT_DIR<span class="sc">}</span><span class="ch">\\</span><span class="ss">output</span><span class="ch">\\</span><span class="ss">working</span><span class="ch">\\</span><span class="ss">Multilingual_toxic_comment_classifier</span><span class="ch">\\</span><span class="ss">"</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co">## Create a destination path for our target model</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>multilingual_toxic_comment_model_dir_destination <span class="op">=</span> multilingual_toxic_comment_demo_path</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co">## Try to move the file</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Attempting to move the </span><span class="sc">{</span>multilingual_toxic_comment_model_dir_path<span class="sc">}</span><span class="ss"> to </span><span class="sc">{</span>multilingual_toxic_comment_model_dir_destination<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">## Move the model</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>    shutil.move(src<span class="op">=</span>multilingual_toxic_comment_model_dir_path,</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>           dst<span class="op">=</span>multilingual_toxic_comment_model_dir_destination)</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Model move completed"</span>)</span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a><span class="co">## If the model has already been moved, check if it exists</span></span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span>:</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"No model found at </span><span class="sc">{</span>multilingual_toxic_comment_model_dir_path<span class="sc">}</span><span class="ss">, perhaps it's already moved."</span>)</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Model already exists at </span><span class="sc">{</span>multilingual_toxic_comment_model_dir_destination<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>multilingual_toxic_comment_model_dir_destination<span class="sc">.</span>exists()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Attempting to move the E:\MultiLingual-Toxic-Comment-Classification\output\working\Multilingual_toxic_comment_classifier\ to E:\MultiLingual-Toxic-Comment-Classification\demos\multilingual_toxic_comment_files
Model move completed</code></pre>
</div>
</div>
</section>
</section>
<section id="turning-our-gradio-app-into-a-python-script-app.py" class="level2">
<h2 class="anchored" data-anchor-id="turning-our-gradio-app-into-a-python-script-app.py">Turning our Gradio App into a Python Script (<code>app.py</code>)</h2>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Now if we look into which directory we are currently, we'll find that using the following code</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>os.getcwd()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>'E:\\MultiLingual-Toxic-Comment-Classification\\notebooks'</code></pre>
</div>
</div>
<p>Now we will move into the demos directory where we will write some helper utilities.</p>
<p>In <code>cd ../demos/</code>: <code>..</code> means we are moving outside of the notebooks directory. <code>demos/</code>: means we moving inside the demos directory.</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>cd ..<span class="op">/</span>demos<span class="op">/</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>E:\MultiLingual-Toxic-Comment-Classification\demos</code></pre>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gradio <span class="im">as</span> gr</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>model_save_path <span class="op">=</span> <span class="st">"Multilingual_toxic_comment_classifier/"</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="co">### Loading the fine-tuned model </span><span class="al">###</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>loaded_model <span class="op">=</span> tf.keras.models.load_model(model_save_path)</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="co">### Initializing the tokenizer </span><span class="al">###</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>tokenizer_ <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"xlm-roberta-large"</span>)</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>examples_list <span class="op">=</span> [</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>    [example]</span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> example <span class="kw">in</span> pd.read_csv(<span class="st">"examples/sample_comments.csv"</span>)[<span class="st">"comment_text"</span>].tolist()</span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prep_data(text, tokenizer, max_len<span class="op">=</span><span class="dv">192</span>):</span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> tokenizer(</span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>        text,</span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span>max_len,</span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a>        truncation<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a>        padding<span class="op">=</span><span class="st">"max_length"</span>,</span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a>        add_special_tokens<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a>        return_tensors<span class="op">=</span><span class="st">"tf"</span>,</span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb45-29"><a href="#cb45-29" aria-hidden="true" tabindex="-1"></a>        <span class="st">"input_ids"</span>: tokens[<span class="st">"input_ids"</span>],</span>
<span id="cb45-30"><a href="#cb45-30" aria-hidden="true" tabindex="-1"></a>        <span class="st">"attention_mask"</span>: tokens[<span class="st">"attention_mask"</span>],</span>
<span id="cb45-31"><a href="#cb45-31" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb45-32"><a href="#cb45-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-33"><a href="#cb45-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-34"><a href="#cb45-34" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(text):</span>
<span id="cb45-35"><a href="#cb45-35" aria-hidden="true" tabindex="-1"></a>    prob_of_toxic_comment <span class="op">=</span> loaded_model.predict(</span>
<span id="cb45-36"><a href="#cb45-36" aria-hidden="true" tabindex="-1"></a>        prep_data(text<span class="op">=</span>text, tokenizer<span class="op">=</span>tokenizer_, max_len<span class="op">=</span><span class="dv">192</span>)</span>
<span id="cb45-37"><a href="#cb45-37" aria-hidden="true" tabindex="-1"></a>    )[<span class="dv">0</span>][<span class="dv">0</span>]</span>
<span id="cb45-38"><a href="#cb45-38" aria-hidden="true" tabindex="-1"></a>    prob_of_non_toxic_comment <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> prob_of_toxic_comment</span>
<span id="cb45-39"><a href="#cb45-39" aria-hidden="true" tabindex="-1"></a>    prob_of_toxic_comment, prob_of_non_toxic_comment</span>
<span id="cb45-40"><a href="#cb45-40" aria-hidden="true" tabindex="-1"></a>    probs <span class="op">=</span> {</span>
<span id="cb45-41"><a href="#cb45-41" aria-hidden="true" tabindex="-1"></a>        <span class="st">"prob_of_toxic_comment"</span>: <span class="bu">float</span>(prob_of_toxic_comment),</span>
<span id="cb45-42"><a href="#cb45-42" aria-hidden="true" tabindex="-1"></a>        <span class="st">"prob_of_non_toxic_comment"</span>: <span class="bu">float</span>(prob_of_non_toxic_comment),</span>
<span id="cb45-43"><a href="#cb45-43" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb45-44"><a href="#cb45-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> probs</span>
<span id="cb45-45"><a href="#cb45-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-46"><a href="#cb45-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-47"><a href="#cb45-47" aria-hidden="true" tabindex="-1"></a>interface <span class="op">=</span> gr.Interface(</span>
<span id="cb45-48"><a href="#cb45-48" aria-hidden="true" tabindex="-1"></a>    fn<span class="op">=</span>predict,</span>
<span id="cb45-49"><a href="#cb45-49" aria-hidden="true" tabindex="-1"></a>    inputs<span class="op">=</span>gr.components.Textbox(lines<span class="op">=</span><span class="dv">4</span>, label<span class="op">=</span><span class="st">"Comment"</span>),</span>
<span id="cb45-50"><a href="#cb45-50" aria-hidden="true" tabindex="-1"></a>    outputs<span class="op">=</span>[gr.Label(label<span class="op">=</span><span class="st">"Probabilities"</span>)],</span>
<span id="cb45-51"><a href="#cb45-51" aria-hidden="true" tabindex="-1"></a>    examples<span class="op">=</span>examples_list,</span>
<span id="cb45-52"><a href="#cb45-52" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span><span class="st">"Multi-Lingual Toxic Comment Classification."</span>,</span>
<span id="cb45-53"><a href="#cb45-53" aria-hidden="true" tabindex="-1"></a>    description<span class="op">=</span><span class="st">"XLM-Roberta Large model"</span>,</span>
<span id="cb45-54"><a href="#cb45-54" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb45-55"><a href="#cb45-55" aria-hidden="true" tabindex="-1"></a>interface.launch(debug<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overwriting multilingual_toxic_comment_files/app.py</code></pre>
</div>
</div>
<section id="creating-a-requirements.txt-file-for-our-gradio-apprequirements.txt" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-requirements.txt-file-for-our-gradio-apprequirements.txt">Creating a requirements.txt file for our Gradio App(<code>requirements.txt</code>)</h3>
<p>This is the last file we need to create for our application.</p>
<p>This file contains all the necessary packages for our Gradio application.</p>
<p>When we deploy our demo app to HuggingFace Spaces, it will search through this file and install the dependencies we mention so our appication can run.</p>
<ol type="1">
<li><code>tensorflow==2.12</code></li>
<li><code>pandas==1.5.2</code></li>
<li><code>gradio==3.1.4</code></li>
<li><code>transformers==4.28.1</code></li>
</ol>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>writefile multilingual_toxic_comment_files<span class="op">/</span>requirements.txt</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>tensorflow<span class="op">==</span><span class="fl">2.12</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>pandas<span class="op">==</span><span class="fl">1.5.2</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>gradio<span class="op">==</span><span class="fl">3.1.4</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>transformers<span class="op">==</span><span class="fl">4.28.1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Overwriting multilingual_toxic_comment_files/requirements.txt</code></pre>
</div>
</div>
</section>
</section>
<section id="deploying-our-application-to-huggingface-spaces" class="level2">
<h2 class="anchored" data-anchor-id="deploying-our-application-to-huggingface-spaces">Deploying our Application to HuggingFace Spaces</h2>
<p>To deploy our demo, there are 2 main options for uploading to HuggingFace Spaces</p>
<ol type="1">
<li><a href="https://huggingface.co/docs/hub/repositories-getting-started#adding-files-to-a-repository-web-ui">Uploading via the Hugging Face Web Interface (easiest)</a></li>
<li><a href="https://huggingface.co/docs/hub/repositories-getting-started#terminal">Uploading via the command line or terminal</a></li>
</ol>
<p>NOTE: To host any application on HuggingFace, we first need to <a href="https://huggingface.co/join">sign up for a free HuggingFace Account</a></p>
<section id="running-our-application-locally" class="level3">
<h3 class="anchored" data-anchor-id="running-our-application-locally">Running our Application locally</h3>
<ol type="1">
<li>Open the terminal or command prompt.</li>
<li>Changing the <code>multilingual_toxic_comment_files</code> directory (cd multilingual_toxic_comment_files).</li>
<li>Creating an environment <code>(python3 -m venv env)</code> or use <code>(python -m venv env)</code>.</li>
<li>Activating the environment <code>(source env/Scripts/activate)</code>.</li>
<li>Installing the <code>requirements.txt</code> using <code>pip install -r requirements.txt</code>. &gt; If faced any errors, we might need to upgrade <code>pip</code> using <code>pip install --upgrade pip</code>.<br>
</li>
<li>Run the app <code>(python3 app.py).</code></li>
</ol>
<p>This should results in a Gradio demo locally at the URL such as : <code>http://127.0.0.1:7860/</code>.</p>
</section>
<section id="uploading-to-hugging-face" class="level3">
<h3 class="anchored" data-anchor-id="uploading-to-hugging-face">Uploading to Hugging Face</h3>
<p>We’ve verified our Melanoma_skin_cancer detection application is working in our local system.</p>
<p>To upload our application to Hugging Face Spaces, we need to do the following.</p>
<ol type="1">
<li><a href="https://huggingface.co/welcome">Sign up</a> for a Hugging Face account.</li>
<li>Start a new Hugging Face Space by going to our profile at the top right corner and then select <a href="https://huggingface.co/new-space">New Space</a>.</li>
<li>Declare the name to the space like <code>Chirag1994/multilingual_toxic_comment_classification_app</code>.</li>
<li>Select a license (I am using MIT license).</li>
<li>Select Gradio as the Space SDK (software development kit).</li>
<li>Choose whether your Space is Public or Private (I am keeping it Public).</li>
<li>Click Create Space.</li>
<li>Clone the repository locally by running: <code>git clone https://huggingface.co/spaces/[YOUR_USERNAME]/[YOUR_SPACE_NAME]</code> in the terminal or command prompt. In our case mine would be like - <code>git clone https://huggingface.co/spaces/Chirag1994/multilingual_toxic_comment_classification_app</code>.</li>
<li>Copy/Move the contents of the downloaded <code>multilingual_toxic_comment_classification_app</code> folder to the cloned repo folder.</li>
<li>To upload files and track larger files (e.g., files that are greater than 10MB) for them we need to <a href="https://git-lfs.github.com/">install Git LFS</a> which stands for Git large File Storage.</li>
<li>Open up the cloned directory using VS code (I’m using VS code), and use the terminal (git bash in my case) and after installing the git lfs, use the command <code>git lfs install</code> to start tracking the file that we want to track. For example - git lfs track <code>"Multilingual_toxic_comment_classifier" directory files</code>.</li>
<li>Create a new .gitignore file and the files &amp; folders that we don’t want git to track like :
<ul>
<li><code>__pycache__/</code></li>
<li><code>.vscode/</code></li>
<li><code>venv/</code></li>
<li><code>.gitignore</code></li>
<li><code>.gitattributes</code></li>
</ul></li>
<li>Add the rest of the files and commit them with:
<ul>
<li><code>git add .</code></li>
<li><code>git commit -m "commit message that you want"</code></li>
</ul></li>
<li>Push(load) the files to Hugging Face
<ul>
<li><code>git push</code></li>
</ul></li>
<li>It might a couple of minutes to finish and then the app will be up and running.</li>
</ol>
</section>
</section>
<section id="our-final-application-deployed-on-huggingface-spaces" class="level2">
<h2 class="anchored" data-anchor-id="our-final-application-deployed-on-huggingface-spaces">Our Final Application deployed on HuggingFace Spaces</h2>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># IPython is a library to help make Python interactive</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> IFrame</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Embed FoodVision Mini Gradio demo</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>IFrame(src<span class="op">=</span><span class="st">"https://chirag1994-multilingual-toxic-comment-classifier.hf.space"</span>, width<span class="op">=</span><span class="dv">1000</span>, height<span class="op">=</span><span class="dv">800</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">

        <iframe width="1000" height="800" src="https://chirag1994-multilingual-toxic-comment-classifier.hf.space" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="Chirag1994/chiragsharma.github.io" data-repo-id="R_kgDOJfJZmg" data-category="General" data-category-id="DIC_kwDOJfJZms4CWR8c" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>